{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<font size=\"+1\">\n",
        "<font color='red'>\n",
        "<b> IMPORTANT NOTE: </b> \n",
        "</font>\n",
        "Make sure to save a copy of this notebook in your personal drive to maintain the changes you make!\n",
        "</font>"
      ],
      "metadata": {
        "id": "nbLhMQUD6vYd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YscaZJH5SNa7"
      },
      "source": [
        "Run the following cells to prepare your working environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSt20IMISNa-"
      },
      "outputs": [],
      "source": [
        "#@title Clone Repo & Install Requirements { display-mode: \"form\" }\n",
        "%%capture\n",
        "\n",
        "# Clone Repo\n",
        "%cd /content\n",
        "!git clone https://github.com/mhsotoudeh/ProbUNet-Tutorial.git\n",
        "# !export PYTHONPATH=\"${PYTHONPATH}:$PWD/ProbUNet-Tutorial\"\n",
        "%cd /content/ProbUNet-Tutorial\n",
        "\n",
        "# Install Requirements\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8dT8wgqTrfZ"
      },
      "outputs": [],
      "source": [
        "#@title Imports { display-mode: \"form\" }\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "from data import *\n",
        "from model import *\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "import gdown\n",
        "\n",
        "from IPython import display\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqb91VMgTri-"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device is {}\".format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TbkjgIQSNbA",
        "tags": []
      },
      "source": [
        "# Part 1: Using Hierarchical Probabilistic U-Net for Source Reconstruction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m59TEkHzT__5",
        "tags": []
      },
      "source": [
        "## Tensorboard Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qY8H4eQUT_ac"
      },
      "outputs": [],
      "source": [
        "# Used to visualize training\n",
        "# %tensorboard --logdir runs/part1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "WzlmiCMdxgO9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select desired resolution and run the following cell."
      ],
      "metadata": {
        "id": "mNdm1j9U_Iec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download { display-mode: \"form\" }\n",
        "resolution = '16' #@param ['16', '32', '64']\n",
        "\n",
        "# Create data directory\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "# Set File ID\n",
        "if resolution == '16':\n",
        "    file_id = '1p8uCmPFvC4KWFVSjdUyqafQ7niUHmUDc&confirm=t'\n",
        "elif resolution == '32':\n",
        "    file_id = '1KIOwnlnwcwc76G-VFA3Y8-nvpMhDayVr&confirm=t'\n",
        "elif resolution == '64':\n",
        "    file_id = '1WhD8JiZ2bty1Pq_T7hg-oX8jB5Q_chx_&confirm=t'\n",
        "\n",
        "# Download File\n",
        "gdown.download(id=file_id, output='data/data.zip', quiet=False)\n",
        "\n",
        "# Unzip File\n",
        "!unzip data/data.zip -d data/"
      ],
      "metadata": {
        "id": "5Z__y4QhxbxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MVc5Pel6cyd"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MDmgTHIT_S8"
      },
      "outputs": [],
      "source": [
        "# First, set your desired dataset, model architecture and training hypermaramters in a run script\n",
        "# Then, execute it using the following command to start training :-)\n",
        "\n",
        "# !./training_scripts/run.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "FF9xOoaY6cyf"
      },
      "source": [
        "## Visualizing Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYlWksKW6cyg"
      },
      "outputs": [],
      "source": [
        "#@title Required Functions { display-mode: \"form\" }\n",
        "\n",
        "# function to plot a given prediction (idx) of a given example (ex) in the dataset\n",
        "def plot_sample(ex, idx, observations, truths, preds, bounds=None, common_pred_colormap=True, show=False):\n",
        "\n",
        "    # Concatenate the observations, ground truth, and predictions into a single tensor (to calculate common color axis limits)\n",
        "    _all = torch.cat([observations[ex], truths[ex], preds[ex]], dim=0)\n",
        "    \n",
        "    # Convert torch tensors to numpy arrays\n",
        "    observation = observations[ex].squeeze().cpu().numpy()\n",
        "    truth = truths[ex].squeeze().cpu().numpy()\n",
        "    preds = preds[ex].cpu().numpy()\n",
        "\n",
        "    # Determine color axis limits\n",
        "    if bounds is None:\n",
        "        _min, _max = _all.min(), _all.max()\n",
        "    else:\n",
        "        _min, _max = bounds\n",
        "    pred_min, pred_max = _min if common_pred_colormap is True else preds.min(), _max if common_pred_colormap is True else preds.max()\n",
        "\n",
        "    # Create a figure with five subplots\n",
        "    fig, axs = plt.subplots(1, 5, figsize=(25,5))\n",
        "\n",
        "    # Set the titles for each subplot\n",
        "    fig.suptitle('Training Example {}'.format(ex+1), size=14)\n",
        "    axs[0].set_title('Observation')\n",
        "    axs[1].set_title('Ground Truth')\n",
        "    axs[2].set_title('Prediction {}'.format(idx+1))\n",
        "    axs[3].set_title('Mean')\n",
        "    axs[4].set_title('STD')\n",
        "\n",
        "    # Display the observation, ground truth, prediction, mean and std maps\n",
        "    im0 = axs[0].imshow(observation, vmin=_min, vmax=_max)\n",
        "    im1 = axs[1].imshow(truth, vmin=_min, vmax=_max)\n",
        "    im2 = axs[2].imshow(preds[idx], vmin=pred_min, vmax=pred_max)\n",
        "    im3 = axs[3].imshow(preds.mean(axis=0), vmin=pred_min, vmax=pred_max)\n",
        "    im4 = axs[4].imshow(preds.std(axis=0))\n",
        "\n",
        "    # Create a list of image objects to be used for color bar display\n",
        "    imlist = [im0, im1, im2, im3, im4]\n",
        "    \n",
        "    # For each subplot, turn off the axes, create a new axis for the color bar, and add it to the figure\n",
        "    for i, axi in enumerate(axs.ravel()):\n",
        "        axi.set_axis_off()\n",
        "\n",
        "        divider = make_axes_locatable(axi)\n",
        "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
        "        fig.colorbar(imlist[i], cax=cax, orientation='vertical')\n",
        "\n",
        "    # If the show parameter is True, display the plot\n",
        "    if show is True:\n",
        "        plt.show()\n",
        "\n",
        "    # Close the figure and return it\n",
        "    plt.close()\n",
        "    return fig\n",
        "\n",
        "\n",
        "# function to creat an animation of \"num\" predictions of a given example (ex) in the dataset\n",
        "def animate_samples(ex, observations, truths, preds, bounds=None, common_pred_colormap=True, num=None, output_type='jshtml'):\n",
        "    # Make sure the number of predictions to display is less than or equal to the total number of available predictions\n",
        "    if num is not None:\n",
        "        assert num <= preds.shape[1]\n",
        "        \n",
        "    # Concatenate the observations, ground truth, and predictions into a single tensor (to calculate common color axis limits)\n",
        "    _all = torch.cat([observations[ex], truths[ex], preds[ex]], dim=0)\n",
        "    \n",
        "    # Convert torch tensors to numpy arrays\n",
        "    observation = observations[ex].squeeze().cpu().numpy()\n",
        "    truth = truths[ex].squeeze().cpu().numpy()\n",
        "    preds = preds[ex].cpu().numpy()\n",
        "    \n",
        "    # Determine color axis limits\n",
        "    if bounds is None:\n",
        "        _min, _max = _all.min(), _all.max()\n",
        "    else:\n",
        "        _min, _max = bounds\n",
        "    pred_min, pred_max = _min if common_pred_colormap is True else preds.min(), _max if common_pred_colormap is True else preds.max()\n",
        "    \n",
        "    # Create a figure with five subplots\n",
        "    fig, axs = plt.subplots(1, 5, figsize=(21.5,4.3))\n",
        "    \n",
        "    # Set the titles for each subplot\n",
        "    fig.suptitle('Training Example {}'.format(ex+1), size=14)\n",
        "    axs[0].set_title('Observation')\n",
        "    axs[1].set_title('Ground Truth')\n",
        "    axs[2].set_title('Prediction 1')\n",
        "    axs[3].set_title('Mean')\n",
        "    axs[4].set_title('STD')\n",
        "    \n",
        "    # Display the observation, ground truth, prediction, mean and std maps\n",
        "    im0 = axs[0].imshow(observation, vmin=_min, vmax=_max)\n",
        "    im1 = axs[1].imshow(truth, vmin=_min, vmax=_max)\n",
        "    im2 = axs[2].imshow(preds[0], vmin=pred_min, vmax=pred_max)\n",
        "    im3 = axs[3].imshow(preds.mean(axis=0), vmin=pred_min, vmax=pred_max)\n",
        "    im4 = axs[4].imshow(preds.std(axis=0), cmap='viridis')\n",
        "\n",
        "    # Create a list of image objects to be used for color bar display\n",
        "    imlist = [im0, im1, im2, im3, im4]\n",
        "    \n",
        "    # For each subplot, turn off the axes, create a new axis for the color bar, and add it to the figure\n",
        "    for i, axi in enumerate(axs.ravel()):\n",
        "        axi.set_axis_off()\n",
        "\n",
        "        divider = make_axes_locatable(axi)\n",
        "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
        "        fig.colorbar(imlist[i], cax=cax, orientation='vertical')\n",
        "    \n",
        "    # Function to update the prediction subplot for each frame of the animation\n",
        "    def animate(i):\n",
        "        axs[2].set_title('Prediction {}'.format(i+1))\n",
        "        im2 = axs[2].imshow(preds[i], vmin=pred_min, vmax=pred_max, animated=True)\n",
        "\n",
        "        return im2,\n",
        "    \n",
        "    # Set the total number of frames\n",
        "    frms = num if num is not None else preds.shape[1]    \n",
        "    \n",
        "    # Set the padding of the plot\n",
        "    plt.tight_layout(pad=2)\n",
        "    \n",
        "    # Generate animation frames\n",
        "    anim = animation.FuncAnimation(fig, animate, frames=frms, interval=100, blit=True, repeat_delay=1000)\n",
        "    \n",
        "    # Close the figure\n",
        "    plt.close()\n",
        "    \n",
        "    # Genrate an return the animation output\n",
        "    if output_type == 'video':\n",
        "        out = anim.to_html5_video()\n",
        "    elif output_type == 'jshtml':\n",
        "        out = anim.to_jshtml()\n",
        "\n",
        "    html = display.HTML(out)\n",
        "    return html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E0PrllgT_d0"
      },
      "outputs": [],
      "source": [
        "#@title Set Parameters + Select Model & Dataset { display-mode: \"both\" }\n",
        "\n",
        "# Set Default Colormap\n",
        "mpl.rc('image', cmap='hot')\n",
        "\n",
        "# Set Random Seed\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Set Parameters\n",
        "bs = 128      # batch size\n",
        "k = 100       # num of predictions per input\n",
        "\n",
        "# Choose Model\n",
        "model_dir = 'pretrained_models'\n",
        "model_stamp = '16_elbo'\n",
        "model_suffix = ''\n",
        "\n",
        "# Choose Data File\n",
        "data_dir = 'data'\n",
        "dataset_name = '16_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIbGlJSp6cyl"
      },
      "outputs": [],
      "source": [
        "#@title Load Model & Data { display-mode: \"both\" }\n",
        "\n",
        "# Load Model & Loss\n",
        "model = torch.load('{}/{}/model{}.pth'.format(model_dir, model_stamp, model_suffix), map_location=torch.device(device))\n",
        "model.eval()\n",
        "\n",
        "criterion = torch.load('{}/{}/loss{}.pth'.format(model_dir, model_stamp, model_suffix), map_location=torch.device(device))\n",
        "criterion.eval()\n",
        "\n",
        "\n",
        "# Load Args\n",
        "with open('{}/{}/args.json'.format(model_dir, model_stamp), 'r') as f:\n",
        "    args = json.load(f)\n",
        "\n",
        "\n",
        "# Load Data\n",
        "test_data, transdict = prepare_data('{}/{}.npy'.format(data_dir, dataset_name), normalization=None)\n",
        "test_loader = DataLoader(test_data, batch_size=bs, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8086MAA-6cym"
      },
      "outputs": [],
      "source": [
        "#@title Generate a Batch of Predictions { display-mode: \"both\" }\n",
        "\n",
        "data_iterator = iter(test_loader)\n",
        "\n",
        "observations, truths = next(data_iterator)\n",
        "observations, truths = observations.to(device), truths.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds_prior, infodicts_prior = model(observations, truths, times=k, insert_from_postnet=False)\n",
        "    preds_post, infodicts_post = model(observations, truths, times=k, insert_from_postnet=True)\n",
        "\n",
        "# Check Shapes\n",
        "observations.shape, truths.shape, preds_prior.shape, preds_post.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEt3YAOP6cyn"
      },
      "outputs": [],
      "source": [
        "#@title Visualize Predictions (Using PriorNet Latents) { display-mode: \"both\" }\n",
        "\n",
        "# plot_sample(ex=12, idx=17,\n",
        "#             observations=observations, truths=truths, preds=preds_prior,\n",
        "#             common_pred_colormap=True)\n",
        "\n",
        "\n",
        "## Specify an arbitrary ex in range (0,127)\n",
        "html = animate_samples(ex=12,\n",
        "                       observations=observations, truths=truths, preds=preds_prior, num=30,\n",
        "                       output_type='jshtml')\n",
        "display.display(html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyiwAwWp6cyn"
      },
      "outputs": [],
      "source": [
        "#@title Visualize Predictions (Using PosteriorNet Latents) { display-mode: \"both\" }\n",
        "\n",
        "# plot_sample(ex=12, idx=17,\n",
        "#             observations=observations, truths=truths, preds=preds_post,\n",
        "#             common_pred_colormap=True)\n",
        "\n",
        "\n",
        "## Specify an arbitrary ex in range (0,127)\n",
        "html = animate_samples(ex=12,\n",
        "                       observations=observations, truths=truths, preds=preds_post, num=30,\n",
        "                       output_type='jshtml')\n",
        "display.display(html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIREmmC86cyo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "vscode": {
      "interpreter": {
        "hash": "542747cc2be5538a1f88007e17e0e28d6a3152d700f3cfeb87b0d7bb983173ce"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}